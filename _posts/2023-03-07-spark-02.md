---
layout: single
title: "Apache Spark란?"
category: "BigData"
tag: [spark]
author_profile: false
sidebar:
  nav: "docs"
---

# Spark 소개 :
Spark, Spark 구성 컴포넌트, 실행 과정

## 1. Spark에 대하여

Spark는 Hadoop의 맵리듀스보다 최대 100배 빠른 성능을 가지고 있다는 점이 가장 큰 특징이다. 먼저, Spark 이전에 많이 사용한 Hadoop의 맵리듀스에 대해 알아보자.

### 1.1. Hadoop

#### 1) Hadoop 구성

- Apache Hadoop은 분산 컴퓨팅용 자바 기반 오픈소스 프레임워크다.
- 하둡 분산 파일시스템 + 맵리듀스 처리 엔진로 구성되어 있다.
- 분산 컴퓨팅을 최초로 대중화하는 데 성공했으며, 하둡 클러스터는 상용 하드웨어를 사용해 쉽게 구축 가능하다.

#### 2) 맵리듀스가 해결한 분산처리 문제

- **병렬 처리** : 전체 연산을 잘게 나누어 동시에 처리
- **데이터 분산** : 데이터를 여러 노드로 분산
- **장애 내성** : 분산 컴포넌트의 장애에 대응

#### 3) 맵리듀스의 한계

- 반복 알고리즘에 적합하지 않다.
  - 맵리듀스 잡의 결과를 다른 잡에서 사용해야 하는 경우 HDFS에 저장해야 하고, 잡에 필요한 데이터를 디스크에서 매번 가져와야 함
- 모든 문제를 맵과 리듀스 연산으로 분해할 수 없다.

### 1.2. Spark란?

- Apache Spark는 고속 범용 분산 컴퓨팅 플랫폼이다.
- 데이터를 메모리에 캐시로 저장하는 인메모리 실행 모델이다.
  - 맵리듀스보다 약 100배 빠른 속도로 작업을 수행한다.
- 대량의 노드에 분산된 데이터 참조 가능하며, 분산 데이터의 실제 위치 적절히 추상화할 수 있다.

### 1.3. Spark의 장단점

#### 1) 장점

- 사용 편의성이 좋다.
  - 스칼라, 자바, 파이썬, R 등의 다양한 프로그래밍 언어 지원
  - 대화형 콘솔인 스카프 셸(스파크 REPL)로 테스트 용이
  - Standalone, YARN, Mesos 등 다양한 유형의 클러스터 매니저 지원

- 통합 플랫폼이다.
  - 단일 프레임워크 내 여러 기능이 통합
  - 일괄 처리 기능 + 실시간 데이터 처리 기능 + 정형 데이터 처리 기능 + 그래프 알고리즘 + 머신 러닝 알고리즘
- 일괄 처리 작업이나 온라인 분석 처리(OLAP) 작업에 적합하다.

#### 2) 단점

- 작은 데이터셋 처리 경우에는 다른 프레임워크 사용이 보다 효율적이다.
  - 잡과 태스크 시작하는 데 시간 소모
- 비동기적으로 갱신하는 연산에는 적합하지 않다.
  - 온라인 트랜잭션 처리(OLTP) 등의 대량의 원자성 트랜잭션을 빠르게 처리해야 하는 작업
    - 비동기 : 응답여부에 상관없이 프로세스 진행
    - 동기 : 앞 프로세스가 완료되었다는 응답을 받아야 뒤 프로세스 진행

## 2. Spark 구성 컴포넌트

Spark 컴포넌트에는 스파크 Core, 스파크 SQL, 스파크 Streaming, 스파크 GraphX, 스파크 MLlib이 있다.

### 2.1. 스파크 Core

- 파일 시스템(HDFS, GluterFS, S3) > 스파크 코어

- 스파크 코어는 스파크 잡과 다른 스파크 컴포넌트에 필요한 기본 기능을 제공한다.
  - 다양한 파일 시스템(HDFS, GluterFS, S3)에 접근 가능
  - 노드 간의 정보 공유, 네트워크, 보안, 스케줄링 및 데이터 셔플링 등
  - 스파크 SQL : DataFrame에 적용된 연산을 일정 시점에 RDD 연산으로 변환해 스파크 잡으로 실행
  - 스파크 Streaming : DStream을 사용해 주기적으로 RDD를 생성
  - 스파크 MLlib : 데이터 타입으로 RDD 사용 (스파크 ML은 DataFrame)
- 스파크 API의 핵심 요소 : RDD(Resilient Distributed Dataset)
  - 분산 데이터 컬렉션을 추상화한 객체
  - 연산 및 변환 메서드를 함께 제공
  - 노드에 장애가 발생해도 재구성 가능

### 2.2. 스파크 SQL

- 데이터 소스(Hive, JSON, RDB, NoSQL, parquet) > 스파크 SQL
- HiveQL을 사용해 대규모 분산 정형 데이터를 다룰 수 있다.
- 다양한 정형 데이터를 처리 가능하다.
  - parquet : 데이터와 스키마를 함께 저장할 수 있는 파일 포맷

- 카탈리스트(Catalyst)라는 쿼리 최적화 프레임워크를 제공한다.

### 2.3. 스파크 Streaming

- 스트리밍 데이터(Kafka, Flume, HDFS) > 스파크 Streaming
- 다양한 데이터 소스에서 유입되는 실시간 스트리밍 데이터를 처리하는 프레임워크다.
- 장애가 발생하면 연산 결과를 자동으로 복구한다.
- 이산 스트림(Discretized Stream, DStream) 방식으로 데이터를 표현한다.
- 실시간 처리 연산과 머신 러닝 작업, SQL 연산, 그래프 연산 등을 통합할 수 있따.

### 2.4. 스파크 MLlib

- 머신러닝 알고리즘 라이브러리다.
  - 로지스틱 회귀, 나이브 베이즈 분류, 서포트 벡터 머신, 의사 결정 트리, 랜덤 포레스트, 선형 회귀, k-평균 군집화 등

### 2.5. 스파크 GraphX

- 그래프 RDD 형태의 그래프 구조를 만들 수 있는 다양한 기능을 제공한다.
  - 그래프 : 정점과 간선(두 정점을 잇는 선)으로 구성된 데이터 구조
- 그래프 알고리즘과 프리겔을 제공한다.
  - 그래프 알고리즘 : 페이지랭크, 연결요소, 최단 경로 탐색, SVD++ 등
  - 프리겔(Pregel) : 대규모 그래프 처리 및 메시지 전달 API

### 2.6. 하둡 생태계와 Spark

- 하둡 생태계란, 하둡과 연동해 빅데이터 연산에 활용하는 다양한 도구와 언어를 의미한다.
- 하둡 생태계에는 인프라 도구, 인터페이스 도구, 분석 도구, 관리 도구 등이 존재한다.
  - 인프라 도구 : 기본적인 데이터 스토리지, 동기화, 스케줄링 함수 제공 (HBase, 주키퍼, 우지)
  - 클러스터 관리 도구 : 암바리
  - 분석 도구 : 데이터 변환 및 조작 함수 (머하웃, 지라프, 피그, 하이브, 임팔라, 드릴)
  - 인터페이스 도구 : 하둡과 다른 시스템 간 데이터 전송 (스쿱, 스톰)
- 이런 하둡 생태계 내에서 스파크는 분석 도구와 인터페이스 도구를 대체할 수 있다.
- 분석 도구 중 임팔라나 드릴의 경우 스파크 코어와 스파크 SQL 기능을 포괄하며, 스파크와는 다른 장점이 있기 때문에 경쟁 프레임워크와 같다.

## 3. Spark 프로그램 실행 과정

### 3.1. 기본 용어

- 블록 : HDFS 각 노드에 분산 저장되어 있는 데이터 청크(128MB)
- 파티션 : 각 노드의 RAM 메모리에 저장된 블록
- 분산 컬렉션 : 파티션의 집합, RDD가 참조함
- cache : 다른 잡을 수행할 때도 RDD가 메모리에 계속 유지되도록 지정
  - 해당 객체를 재사용해서 추가 분석 가능

### 3.2. 실행 과정

- 사용자가 스파크 셸 시작하면 스파크 클러스터에 연결된다.
- 사용자가 데이터 변수에 불러오면 HDFS 에 저장된 블록을 각 노드 RAM에 로드된다.
  - 스파크가 각 블록이 저장된 위치를 하둡에게 요청
    - 사용자가 분산 저장된 데이터의 위치를 알 필요가 없음
  - 모든 블록을 하둡 클러스터 노드의 RAM 메모리로 전송 (파티션)
    - 데이터 지역성 달성으로 대량의 데이터를 네트워크로 전송할 필요가 없음
- 사용자가 함수를 호출하면 파티션 집합에 RDD API 사용한다.
  - RDD의 컬렉션을 필터링, 사용자 정의 함수로 컬렉션 매핑, 누적 값 하나로 리듀스, 두 RDD 교차 및 결합과 같은 작업 가능
  - cache를 활용하여 다른 잡을 수행할 때도 RDD가 메모리에 계속 유지

## 4. 생각

- 다양한 데이터 분산 처리를 한 프레임워크 내에서 할 수 있다는 점이 Spark의 장점이다.
- 하지만 인메모리 기반이기 때문에 직접 Spark를 사용해보면, 실행 과정에서 메모리 이슈를 종종 경험하게 된다.
- 메모리 관리를 효율적으로 하면서, 대용량 데이터 배치 처리에 사용하면 효율적인 프레임워크이라고 생각한다.
- 스파크 Steaming은 미니 배치 방식이어서 완전 실시간 데이터를 다루기에는 적합하지 않은데, 과연 실시간 데이터를 머신러닝에 바로 적용시키는 파이프라인에서는 장점을 보일 수 있을지 궁금하다.
  - 스파크 Streaming + 스파크 MLlib 



## REFERENCES

- [서적] 스파크를 다루는 기술 (페타 제체비치, 마르코 보나치)